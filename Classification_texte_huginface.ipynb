{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🚀 Classification de Texte avec Hugging Face Transformers\n",
        "\n",
        "Ce notebook présente un pipeline complet de **classification de texte** utilisant **DistilBERT** et la bibliothèque **Transformers** de Hugging Face.\n",
        "\n",
        "## 📋 Table des Matières\n",
        "1. [Installation des Dépendances](#dependencies)\n",
        "2. [Chargement du Dataset AG News](#dataset)\n",
        "3. [Justification du Choix du Modèle](#model-choice)\n",
        "4. [Tokenisation des Données](#tokenization)\n",
        "5. [Fine-tuning du Modèle](#training)\n",
        "6. [Évaluation des Performances](#evaluation)\n",
        "7. [Sauvegarde du Modèle](#save)\n",
        "8. [Tests de Prédiction](#prediction)\n",
        "\n",
        "## 🎯 Objectif\n",
        "Développer un classifieur de texte capable de **catégoriser automatiquement des articles de presse** en 4 catégories : World, Sports, Business, et Sci/Tech.\n",
        "\n",
        "## 📊 Résultats Attendus\n",
        "- **🎯 Accuracy**: ~92% sur le jeu de test\n",
        "- **📈 Dataset**: AG News (127,600 articles)\n",
        "- **🏗️ Architecture**: DistilBERT fine-tuné\n",
        "- **⚡ Temps d'entraînement**: ~10 epochs\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Installation des Dépendances {#dependencies}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeARVBTshhoy",
        "outputId": "15a79f2f-5c24-49bf-cd06-58ebcf18014c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Bibliothèques installées.\n"
          ]
        }
      ],
      "source": [
        "# Installation des bibliothèques Hugging Face et de scikit-learn pour l'évaluation\n",
        "!pip install -q datasets transformers torch scikit-learn\n",
        "\n",
        "print(\"✅ Bibliothèques installées.\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyagBn4skF8L",
        "outputId": "0dd95608-c2a4-4b84-bf85-94d9b73f2767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (1.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade datasets transformers huggingface-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chargement du Dataset AG News {#dataset}\n",
        "\n",
        "### 📰 À Propos d'AG News\n",
        "Le dataset **AG News** est un benchmark populaire pour la classification de texte :\n",
        "\n",
        "- **📊 Taille**: 127,600 articles de presse\n",
        "- **📋 Classes**: 4 catégories d'actualités\n",
        "- **🎯 Task**: Classification multi-classe\n",
        "- **📈 Split**: 120K train / 7.6K test\n",
        "\n",
        "### 🏷️ Classes Disponibles:\n",
        "1. **World** (0) - Actualités mondiales\n",
        "2. **Sports** (1) - Actualités sportives  \n",
        "3. **Business** (2) - Actualités économiques\n",
        "4. **Sci/Tech** (3) - Sciences et technologie\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7k4Juhjh2NE",
        "outputId": "2068cf37-345b-4add-f51e-894b64e2d370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Jeu de données 'ag_news' chargé avec succès.\n",
            "\n",
            "Structure du jeu de données :\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 120000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 7600\n",
            "    })\n",
            "})\n",
            "\n",
            "--- Exemple de donnée (train) ---\n",
            "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
            "\n",
            "Labels : [(0, 'World'), (1, 'Sports'), (2, 'Business'), (3, 'Sci/Tech')]\n",
            "Texte : 'Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.'\n",
            "Label : 2 (Business)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Chargement du jeu de données AG News\n",
        "try:\n",
        "    raw_datasets = load_dataset(\"ag_news\")\n",
        "    print(\"✅ Jeu de données 'ag_news' chargé avec succès.\")\n",
        "    print(\"\\nStructure du jeu de données :\")\n",
        "    print(raw_datasets)\n",
        "\n",
        "    # Affichage d'un exemple pour comprendre la structure\n",
        "    print(\"\\n--- Exemple de donnée (train) ---\")\n",
        "    example = raw_datasets['train'][0]\n",
        "    print(example)\n",
        "\n",
        "    # Les labels sont des entiers, créons un mappage pour la lisibilité\n",
        "    label_names = raw_datasets['train'].features['label'].names\n",
        "    print(f\"\\nLabels : {list(enumerate(label_names))}\")\n",
        "    print(f\"Texte : '{example['text']}'\")\n",
        "    print(f\"Label : {example['label']} ({label_names[example['label']]})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors du chargement du jeu de données : {e}\")\n",
        "    print(\"Il est possible que le service Hugging Face Hub soit temporairement indisponible.\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rpv-dO2iCDK"
      },
      "source": [
        "Justification du Choix du Modèle : DistilBERT\n",
        "Pour cette tâche, nous allons choisir distilbert-base-uncased. C'est un choix stratégique pour plusieurs raisons :\n",
        "\n",
        "Efficacité : DistilBERT est une version \"distillée\" de BERT. Il est environ 60% plus rapide et plus léger que BERT, tout en conservant plus de 95% de ses performances.\n",
        "Adapté à Colab : Sa légèreté le rend idéal pour un fine-tuning sur des ressources limitées comme celles de Google Colab, permettant des itérations plus rapides.\n",
        "Performance : Il offre un excellent compromis entre vitesse et précision pour les tâches de classification de texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Tokenisation des Données {#tokenization}\n",
        "\n",
        "### 🔤 Processus de Tokenisation\n",
        "\n",
        "La tokenisation transforme le texte brut en tokens numériques compréhensibles par le modèle :\n",
        "\n",
        "#### 🔧 Étapes de Tokenisation:\n",
        "1. **Segmentation**: Division en sous-mots (WordPiece)\n",
        "2. **Mapping**: Conversion en IDs numériques\n",
        "3. **Padding**: Uniformisation de la longueur\n",
        "4. **Truncation**: Limitation à 512 tokens max\n",
        "\n",
        "#### ⚙️ Configuration:\n",
        "- **Tokenizer**: `distilbert-base-uncased`\n",
        "- **Max Length**: 512 tokens\n",
        "- **Padding**: Dynamique à la longueur max du batch\n",
        "- **Truncation**: Activée pour les textes longs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4e92c0a157304f16bd1f2b367685e013",
            "c4fe55fe2ef74d46bdaaa564bcc6e584",
            "f47021eb40304718abb04063a8e558d0",
            "59784759b64f401badd97790c64bcb10",
            "bb50290f95ee48f896dd133b3367d6e4",
            "0f61b1b772b04b378fa01652c929b874",
            "7a68b3673f564bfabcb221b05b75812e",
            "4611d6f6e1714ec88394dab266da1120",
            "85a2cc825c9746b6813bcd70b5f7dc2f",
            "3a5ea576dae743e791e33520092068fc",
            "e45f7bc9d4e0490590019541ad7c906e"
          ]
        },
        "id": "lfpNDW0xiD-m",
        "outputId": "a8abd69b-30ed-4a79-fed2-98d257034e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Tokenisation des données en cours...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e92c0a157304f16bd1f2b367685e013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Données tokenisées.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Chargement du tokenizer associé à DistilBERT\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Fonction pour tokeniser les textes\n",
        "def tokenize_function(examples):\n",
        "    # padding=True et truncation=True assurent que toutes les séquences ont la même longueur\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Appliquer la fonction de tokenisation à l'ensemble du jeu de données\n",
        "# batched=True permet de traiter les données par lots pour plus de rapidité\n",
        "print(\"🔄 Tokenisation des données en cours...\")\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "print(\"✅ Données tokenisées.\")\n",
        "\n",
        "# On peut retirer la colonne \"text\" qui n'est plus nécessaire et renommer \"label\" en \"labels\"\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Création de sous-ensembles pour un entraînement plus rapide\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(10000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fine-tuning du Modèle {#training}\n",
        "\n",
        "### 🎯 Configuration d'Entraînement\n",
        "\n",
        "#### ⚙️ Hyperparamètres:\n",
        "- **Learning Rate**: 2e-5 (recommandé pour BERT-family)\n",
        "- **Batch Size**: 16 (train) / 16 (eval)\n",
        "- **Epochs**: 10 (avec early stopping)\n",
        "- **Weight Decay**: 0.01 (régularisation L2)\n",
        "- **Optimizer**: AdamW (optimiseur par défaut)\n",
        "\n",
        "#### 📊 Stratégie d'Entraînement:\n",
        "1. **Subset Training**: 10K échantillons (entraînement rapide)\n",
        "2. **Évaluation**: 1K échantillons de validation\n",
        "3. **Monitoring**: Loss de validation à chaque epoch\n",
        "4. **Sauvegarde**: Meilleur modèle automatiquement sauvé\n",
        "\n",
        "### 🚀 Avantages du Fine-tuning:\n",
        "- **Transfer Learning**: Exploitation des connaissances pré-acquises\n",
        "- **Adaptation**: Spécialisation sur le domaine des actualités\n",
        "- **Efficacité**: Moins de données requises qu'un entraînement from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "NYpszQ1dk0Eg",
        "outputId": "fa92a00e-a5e5-45f5-a0d6-37d146ae4197"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Début du fine-tuning...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6250/6250 17:14, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.284693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.244600</td>\n",
              "      <td>0.296621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.311361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.093200</td>\n",
              "      <td>0.360529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.058100</td>\n",
              "      <td>0.393590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>0.447178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.479264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.521314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.528451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.537483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fine-tuning terminé.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Chargement du modèle pré-entraîné, en spécifiant le nombre de classes (4 pour AG News)\n",
        "# Assurez-vous que la variable 'model_checkpoint' est bien définie (ex: \"distilbert-base-uncased\")\n",
        "# et que 'small_train_dataset' et 'small_eval_dataset' existent.\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4)\n",
        "\n",
        "# Définition des arguments pour l'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"Pipeline-Classification-MLOps/models/huggingFace/results\",\n",
        "\n",
        "    # --- CORRECTION APPLIQUÉE ICI ---\n",
        "    eval_strategy=\"epoch\", # Remplacement de \"evaluation_strategy\" par \"eval_strategy\"\n",
        "    # ---------------------------------\n",
        "\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/TP/huginface/logs',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Création de l'objet Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        ")\n",
        "\n",
        "# Lancement du fine-tuning\n",
        "print(\"\\n🚀 Début du fine-tuning...\")\n",
        "trainer.train()\n",
        "print(\"✅ Fine-tuning terminé.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Évaluation des Performances {#evaluation}\n",
        "\n",
        "### 📊 Métriques d'Évaluation\n",
        "\n",
        "Nous utilisons plusieurs métriques pour évaluer la performance de notre modèle :\n",
        "\n",
        "#### 🎯 Métriques Principales:\n",
        "- **Accuracy**: Pourcentage de prédictions correctes\n",
        "- **Precision**: Exactitude des prédictions positives\n",
        "- **Recall**: Capacité à identifier tous les cas positifs\n",
        "- **F1-Score**: Moyenne harmonique de Precision et Recall\n",
        "\n",
        "#### 📈 Résultats Attendus:\n",
        "- **Accuracy globale**: ~92%\n",
        "- **Performance par classe**: Équilibrée entre les 4 catégories\n",
        "- **Meilleure classe**: Sports (textes distinctifs)\n",
        "- **Plus difficile**: Business vs World (overlap possible)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "uK9kqzuPk2uD",
        "outputId": "99e516a6-f623-4bbc-8068-aec6e3229920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Évaluation des performances sur l'ensemble de test...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Rapport de Classification ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       World       0.96      0.91      0.93       266\n",
            "      Sports       0.98      0.99      0.98       246\n",
            "    Business       0.89      0.87      0.88       246\n",
            "    Sci/Tech       0.84      0.89      0.86       242\n",
            "\n",
            "    accuracy                           0.92      1000\n",
            "   macro avg       0.92      0.92      0.91      1000\n",
            "weighted avg       0.92      0.92      0.92      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\n📊 Évaluation des performances sur l'ensemble de test...\")\n",
        "\n",
        "# Obtenir les prédictions du modèle sur le jeu de test\n",
        "predictions = trainer.predict(small_eval_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "true_labels = small_eval_dataset[\"label\"]\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "print(\"\\n--- Rapport de Classification ---\")\n",
        "print(classification_report(true_labels, predicted_labels, target_names=label_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sauvegarde du Modèle {#save}\n",
        "\n",
        "### 💾 Stratégie de Sauvegarde\n",
        "\n",
        "Le modèle et le tokenizer sont sauvegardés ensemble pour assurer la reproductibilité :\n",
        "\n",
        "#### 🔧 Éléments Sauvegardés:\n",
        "- **Modèle DistilBERT** fine-tuné (.bin)\n",
        "- **Tokenizer** avec vocabulaire (.json)\n",
        "- **Configuration** du modèle (.json)\n",
        "- **Métadonnées** d'entraînement\n",
        "\n",
        "#### 📁 Structure de Sauvegarde:\n",
        "```\n",
        "Pipeline-Classification-MLOps/models/huggingFace/\n",
        "└── text-classifier-ag-news-distilbert/\n",
        "    ├── config.json\n",
        "    ├── pytorch_model.bin\n",
        "    ├── tokenizer_config.json\n",
        "    ├── tokenizer.json\n",
        "    └── vocab.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOe3xkigk4-Q",
        "outputId": "34bce723-2117-41aa-a510-2375c1779680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Modèle et tokenizer sauvegardés dans le dossier : '/content/drive/MyDrive/TP/huginface/text-classifier-ag-news-distilbert'\n"
          ]
        }
      ],
      "source": [
        "# Définition du dossier de sauvegarde\n",
        "output_model_dir = \"Pipeline-Classification-MLOps/models/huggingFace/text-classifier-ag-news-distilbert\"\n",
        "\n",
        "# Sauvegarde du modèle et du tokenizer\n",
        "trainer.save_model(output_model_dir)\n",
        "tokenizer.save_pretrained(output_model_dir)\n",
        "\n",
        "print(f\"\\n✅ Modèle et tokenizer sauvegardés dans le dossier : '{output_model_dir}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Tests de Prédiction en Production {#prediction}\n",
        "\n",
        "### 🧪 Suite de Tests Complète\n",
        "\n",
        "Cette section valide les performances du modèle sur différents types de textes :\n",
        "\n",
        "#### 🎯 Types de Tests:\n",
        "\n",
        "1. **Tests Simples** 🟢\n",
        "   - Textes évidents pour chaque catégorie\n",
        "   - Validation des cas d'usage basiques\n",
        "\n",
        "2. **Tests Ambigus** 🟡\n",
        "   - Articles avec éléments de plusieurs catégories\n",
        "   - Test de la robustesse du modèle\n",
        "\n",
        "3. **Tests Hors Distribution** 🔴\n",
        "   - Textes non-journalistiques (cuisine, etc.)\n",
        "   - Évaluation de la généralisation\n",
        "\n",
        "#### 📊 Métriques de Confiance:\n",
        "- **Très Haute** (>95%): Prédiction fiable\n",
        "- **Haute** (80-95%): Prédiction probable\n",
        "- **Modérée** (60-80%): Incertitude du modèle\n",
        "- **Faible** (<60%): Prédiction peu fiable\n",
        "\n",
        "### 🎯 Objectifs des Tests:\n",
        "- Vérifier la **robustesse** du modèle\n",
        "- Identifier les **cas limites**\n",
        "- Tester la **généralisation** hors domaine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WykfpgfVscR6",
        "outputId": "cd0b4be1-24b1-493a-8c3b-9f1b6c757d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Début du test pour le modèle : /content/drive/MyDrive/TP/huginface/text-classifier-ag-news-distilbert ---\n",
            "🔄 Chargement du modèle et du tokenizer...\n",
            "✅ Modèle et tokenizer chargés avec succès.\n",
            "----------------------------------------\n",
            "🔬 Test en cours : Cas Simple (Sport)\n",
            "   Texte : \"The team won the championship final after a thrilling match.\"\n",
            "\n",
            "--- RÉSULTAT DE LA PRÉDICTION ---\n",
            "🎯 Classe prédite : Sports\n",
            "💯 Confiance : 99.96%\n",
            "----------------------------------------\n",
            "🔬 Test en cours : Cas Simple (Business)\n",
            "   Texte : \"The company's stock price surged after announcing record profits for the quarter.\"\n",
            "\n",
            "--- RÉSULTAT DE LA PRÉDICTION ---\n",
            "🎯 Classe prédite : Business\n",
            "💯 Confiance : 99.95%\n",
            "----------------------------------------\n",
            "🔬 Test en cours : Cas Simple (Sci/Tech)\n",
            "   Texte : \"Researchers have developed a new AI that can write compelling short stories.\"\n",
            "\n",
            "--- RÉSULTAT DE LA PRÉDICTION ---\n",
            "🎯 Classe prédite : Sci/Tech\n",
            "💯 Confiance : 99.91%\n",
            "----------------------------------------\n",
            "🔬 Test en cours : Cas Ambigu (Sport/Business/Tech)\n",
            "   Texte : \"Formula 1 announced new engine regulations powered by sustainable fuels to reduce costs.\"\n",
            "\n",
            "--- RÉSULTAT DE LA PRÉDICTION ---\n",
            "🎯 Classe prédite : World\n",
            "💯 Confiance : 58.57%\n",
            "----------------------------------------\n",
            "🔬 Test en cours : Cas Hors Distribution (Cuisine)\n",
            "   Texte : \"The recipe for this cake requires two cups of flour and a pinch of salt.\"\n",
            "\n",
            "--- RÉSULTAT DE LA PRÉDICTION ---\n",
            "🎯 Classe prédite : Sci/Tech\n",
            "💯 Confiance : 95.63%\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# --- Configuration ---\n",
        "# MODIFIEZ CE NOM si votre dossier de modèle est différent\n",
        "MODEL_DIR = \"Pipeline-Classification-MLOps/models/huggingFace/text-classifier-ag-news-distilbert\"\n",
        "\n",
        "# Les noms des classes dans l'ordre de leur index (0, 1, 2, 3)\n",
        "CLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "# --- Phrases de test ---\n",
        "test_sentences = {\n",
        "    \"Cas Simple (Sport)\": \"The team won the championship final after a thrilling match.\",\n",
        "    \"Cas Simple (Business)\": \"The company's stock price surged after announcing record profits for the quarter.\",\n",
        "    \"Cas Simple (Sci/Tech)\": \"Researchers have developed a new AI that can write compelling short stories.\",\n",
        "    \"Cas Ambigu (Sport/Business/Tech)\": \"Formula 1 announced new engine regulations powered by sustainable fuels to reduce costs.\",\n",
        "    \"Cas Hors Distribution (Cuisine)\": \"The recipe for this cake requires two cups of flour and a pinch of salt.\"\n",
        "}\n",
        "\n",
        "\n",
        "def predict(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Effectue une prédiction sur une seule chaîne de caractères.\n",
        "    \"\"\"\n",
        "    # 1. Tokeniser le texte d'entrée\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # 2. Effectuer la prédiction\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # 3. Interpréter les résultats\n",
        "    # Appliquer Softmax pour convertir les logits en probabilités\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    # Obtenir la classe prédite et la confiance\n",
        "    confidence, predicted_class_idx = torch.max(probabilities, dim=-1)\n",
        "    predicted_class = CLASS_NAMES[predicted_class_idx.item()]\n",
        "\n",
        "    return predicted_class, confidence.item()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fonction principale pour charger le modèle et lancer les tests.\n",
        "    \"\"\"\n",
        "    print(f\"--- Début du test pour le modèle : {MODEL_DIR} ---\")\n",
        "\n",
        "    # 1. Vérifier si le dossier du modèle existe\n",
        "    if not os.path.exists(MODEL_DIR):\n",
        "        print(f\"❌ Erreur : Le dossier du modèle '{MODEL_DIR}' n'a pas été trouvé.\")\n",
        "        return\n",
        "\n",
        "    # 2. Charger le modèle et le tokenizer sauvegardés\n",
        "    try:\n",
        "        print(\"🔄 Chargement du modèle et du tokenizer...\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "        print(\"✅ Modèle et tokenizer chargés avec succès.\")\n",
        "        # Mettre le modèle en mode évaluation\n",
        "        model.eval()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur lors du chargement : {e}\")\n",
        "        return\n",
        "\n",
        "    # 3. Lancer les tests sur les différentes phrases\n",
        "    for test_name, sentence in test_sentences.items():\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"🔬 Test en cours : {test_name}\")\n",
        "        print(f\"   Texte : \\\"{sentence}\\\"\")\n",
        "\n",
        "        predicted_class, confidence = predict(sentence, model, tokenizer)\n",
        "\n",
        "        print(\"\\n--- RÉSULTAT DE LA PRÉDICTION ---\")\n",
        "        print(f\"🎯 Classe prédite : {predicted_class}\")\n",
        "        print(f\"💯 Confiance : {confidence:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f61b1b772b04b378fa01652c929b874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5ea576dae743e791e33520092068fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4611d6f6e1714ec88394dab266da1120": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e92c0a157304f16bd1f2b367685e013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4fe55fe2ef74d46bdaaa564bcc6e584",
              "IPY_MODEL_f47021eb40304718abb04063a8e558d0",
              "IPY_MODEL_59784759b64f401badd97790c64bcb10"
            ],
            "layout": "IPY_MODEL_bb50290f95ee48f896dd133b3367d6e4"
          }
        },
        "59784759b64f401badd97790c64bcb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5ea576dae743e791e33520092068fc",
            "placeholder": "​",
            "style": "IPY_MODEL_e45f7bc9d4e0490590019541ad7c906e",
            "value": " 7600/7600 [00:01&lt;00:00, 4762.02 examples/s]"
          }
        },
        "7a68b3673f564bfabcb221b05b75812e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a2cc825c9746b6813bcd70b5f7dc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb50290f95ee48f896dd133b3367d6e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fe55fe2ef74d46bdaaa564bcc6e584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f61b1b772b04b378fa01652c929b874",
            "placeholder": "​",
            "style": "IPY_MODEL_7a68b3673f564bfabcb221b05b75812e",
            "value": "Map: 100%"
          }
        },
        "e45f7bc9d4e0490590019541ad7c906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47021eb40304718abb04063a8e558d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4611d6f6e1714ec88394dab266da1120",
            "max": 7600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85a2cc825c9746b6813bcd70b5f7dc2f",
            "value": 7600
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
