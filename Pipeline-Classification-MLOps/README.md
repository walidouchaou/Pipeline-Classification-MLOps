# ğŸš€ Pipeline Classification MLOps - Classification Multi-Classes

Un pipeline complet de **Machine Learning** utilisant **Deep Learning** et **Transfer Learning** pour deux tÃ¢ches de classification :
- **ğŸ–¼ï¸ Classification d'Images** : 32 catÃ©gories d'objets avec EfficientNetV2B0
- **ğŸ“ Classification de Texte** : 4 catÃ©gories d'actualitÃ©s avec DistilBERT

## ğŸ¯ Objectif

DÃ©velopper des systÃ¨mes robustes de classification incluant :
- âœ… **Images** : Classification multi-classe (32 catÃ©gories)
- âœ… **Texte** : Classification d'actualitÃ©s (4 catÃ©gories)  
- âœ… **Transfer Learning** : EfficientNetV2B0 + DistilBERT
- âœ… **Ã‰valuation complÃ¨te** des performances
- âœ… **Pipeline reproductible** et documentÃ©

## ğŸ“ˆ Performances des ModÃ¨les

### ğŸ–¼ï¸ **Classification d'Images**
- **ğŸ¯ Accuracy**: 100% sur le jeu de test
- **ğŸ“Š Dataset**: 12,155 images, 32 classes
- **ğŸ—ï¸ Architecture**: EfficientNetV2B0 + Transfer Learning
- **âš¡ Temps d'entraÃ®nement**: ~13 epochs (early stopping)

### ğŸ“ **Classification de Texte**
- **ğŸ¯ Accuracy**: ~92% sur le jeu de test
- **ğŸ“Š Dataset**: AG News (127,600 articles, 4 classes)
- **ğŸ—ï¸ Architecture**: DistilBERT fine-tunÃ©
- **âš¡ Temps d'entraÃ®nement**: ~10 epochs

## ğŸ“ Structure du Projet

```
Pipeline-Classification-MLOps/
â”œâ”€â”€ data/                          # DonnÃ©es (auto-tÃ©lÃ©chargÃ©es)
â”œâ”€â”€ models/                        # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”œâ”€â”€ notebooks/                     # Notebooks Jupyter
â”‚   â”œâ”€â”€ classificationMulti_Class.ipynb      # Classification d'images
â”‚   â””â”€â”€ Classification_texte_huginface.ipynb # Classification de texte
â”œâ”€â”€ docs/                          # Documentation
â”œâ”€â”€ reports/                       # Rapports et rÃ©sultats
â”œâ”€â”€ references/                    # RÃ©fÃ©rences et ressources
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ pyproject.toml                 # Configuration du projet
â”œâ”€â”€ Makefile                       # Commandes automatisÃ©es
â””â”€â”€ README.md                      # Ce fichier
```

## ğŸš€ DÃ©marrage Rapide

### 1. Cloner le Projet

```bash
git clone https://github.com/votre-username/Pipeline-Classification-MLOps.git
cd Pipeline-Classification-MLOps
```

### 2. CrÃ©er un Environnement Virtuel

```bash
# CrÃ©ation de l'environnement virtuel
python -m venv venv

# Activation (Windows)
venv\Scripts\activate

# Activation (macOS/Linux)
source venv/bin/activate
```

### 3. Installer les DÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Lancer l'EntraÃ®nement

#### Option A: Via Jupyter Notebook (RecommandÃ©)

```bash
# Lancer Jupyter
jupyter notebook

# Choisir le notebook selon votre tÃ¢che :
# - Classification d'images : notebooks/classificationMulti_Class.ipynb
# - Classification de texte : notebooks/Classification_texte_huginface.ipynb
```

#### Option B: Via Kaggle/Google Colab

1. TÃ©lÃ©charger un des notebooks :
   - `classificationMulti_Class.ipynb` (images)
   - `Classification_texte_huginface.ipynb` (texte)
2. L'importer dans Kaggle ou Google Colab
3. ExÃ©cuter toutes les cellules

## ğŸ“Š Datasets

### ğŸ–¼ï¸ **Images : Classification Dataset - 32 Classes**
- **Source**: [Image Classification Dataset - 32 Classes](https://www.kaggle.com/datasets/anthonytherrien/image-classification-dataset-32-classes)
- **Taille**: 12,155 images
- **Classes**: 32 catÃ©gories variÃ©es
- **Format**: Images de taille variable (redimensionnÃ©es Ã  224Ã—224)

### ğŸ“ **Texte : AG News Dataset**
- **Source**: [AG News Dataset](https://huggingface.co/datasets/ag_news) (Hugging Face)
- **Taille**: 127,600 articles de presse
- **Classes**: 4 catÃ©gories d'actualitÃ©s
- **Format**: Texte brut (tokenisÃ© automatiquement)

### ğŸ“‹ Classes Disponibles

#### ğŸ–¼ï¸ **Images (32 classes)** :
```
['bicycle', 'bird', 'bread', 'car', 'cat', 'dog', 'elephant', 'fish', 
 'flower', 'frog', 'hamburger', 'horse', 'lasagna', 'lion', 'men', 
 'monkey', 'moose', 'motorcycle', 'pencil', 'pickup', 'pizza', 'rabbit', 
 'rat', 'rhinoceros', 'robot', 'shark', 'spaghetti', 'squirrel', 'tiger', 
 'turtle', 'women', 'zebra']
```

#### ğŸ“ **Texte (4 classes)** :
```
['World', 'Sports', 'Business', 'Sci/Tech']
```

## ğŸ—ï¸ Architectures des ModÃ¨les

### ğŸ–¼ï¸ **Images : EfficientNetV2B0 + Transfer Learning**

```python
Model: "functional"
â”œâ”€â”€ Data Augmentation (RandomFlip + RandomRotation)
â”œâ”€â”€ EfficientNetV2B0 (prÃ©-entraÃ®nÃ© ImageNet, frozen)
â”œâ”€â”€ GlobalAveragePooling2D
â”œâ”€â”€ Dropout (0.2)
â””â”€â”€ Dense (32 classes, softmax)
```

**Configuration d'EntraÃ®nement :**
- **Optimiseur**: Adam (lr=0.001)
- **Loss**: Sparse Categorical Crossentropy
- **Batch Size**: 32 | **Input Size**: 224Ã—224Ã—3

### ğŸ“ **Texte : DistilBERT Fine-tunÃ©**

```python
Model: "DistilBertForSequenceClassification"
â”œâ”€â”€ DistilBERT (6 layers, 768 hidden, 12 heads)
â”œâ”€â”€ Pre-classifier (Dense + Dropout)
â””â”€â”€ Classifier (Dense, 4 classes)
```

**Configuration d'EntraÃ®nement :**
- **Optimiseur**: AdamW (lr=2e-5)
- **Loss**: Cross Entropy Loss
- **Batch Size**: 16 | **Max Length**: 512 tokens

## ğŸ“‹ PrÃ©requis

### ğŸ”§ SystÃ¨me
- Python 3.8+
- 8GB+ RAM recommandÃ©s
- GPU optionnel (amÃ©liore les performances)

### ğŸ“¦ DÃ©pendances Principales
```
# Deep Learning
tensorflow>=2.13.0
torch>=2.0.0

# Hugging Face Ecosystem
transformers>=4.30.0
datasets>=2.12.0
tokenizers>=0.13.0
huggingface-hub>=0.15.0

# Data Science
scikit-learn>=1.3.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Environment
jupyter>=1.0.0
kagglehub>=0.2.0
```

## ğŸ® Utilisation

### ğŸ““ Notebooks Disponibles

#### ğŸ–¼ï¸ **Classification d'Images** : `classificationMulti_Class.ipynb`
1. **Installation automatique des dÃ©pendances**
2. **TÃ©lÃ©chargement automatique du dataset** (via kagglehub)
3. **PrÃ©paration des donnÃ©es** (split 80/10/10)
4. **EntraÃ®nement EfficientNetV2B0** avec early stopping
5. **Ã‰valuation complÃ¨te** (accuracy, confusion matrix, classification report)
6. **Sauvegarde du modÃ¨le** (.keras)
7. **Tests de prÃ©diction** sur images rÃ©elles

#### ğŸ“ **Classification de Texte** : `Classification_texte_huginface.ipynb`
1. **Installation des dÃ©pendances Hugging Face**
2. **Chargement du dataset AG News** (automatique)
3. **Tokenisation avec DistilBERT**
4. **Fine-tuning du modÃ¨le** prÃ©-entraÃ®nÃ©
5. **Ã‰valuation des performances** (classification report)
6. **Sauvegarde du modÃ¨le** (.bin + tokenizer)
7. **Tests de prÃ©diction** sur textes variÃ©s

### ğŸ’¾ ModÃ¨les SauvegardÃ©s

AprÃ¨s l'entraÃ®nement, les modÃ¨les sont automatiquement sauvegardÃ©s :

#### ğŸ–¼ï¸ **Images** :
```
models/image_classifier_model.keras
```

#### ğŸ“ **Texte** :
```
models/huggingFace/text-classifier-ag-news-distilbert/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ tokenizer_config.json
â””â”€â”€ tokenizer.json
```

### ğŸ”® PrÃ©diction sur Nouvelles Images

Le notebook inclut une section complÃ¨te de tests avec :
- Tests sur images de base
- Tests de robustesse (classes similaires)
- Tests hors distribution

## ğŸ“Š RÃ©sultats

### ğŸ¯ MÃ©triques de Performance
- **Test Accuracy**: 100%
- **Validation Accuracy**: 100% 
- **Training Time**: ~13 epochs (early stopping)

### ğŸ“ˆ Points Forts
- âœ… Excellent transfer learning
- âœ… Convergence rapide
- âœ… GÃ©nÃ©ralisation parfaite sur le test set
- âœ… Pipeline entiÃ¨rement automatisÃ©

## ğŸ› ï¸ DÃ©veloppement

### ğŸ”„ Relancer l'EntraÃ®nement

Pour relancer un entraÃ®nement avec des paramÃ¨tres diffÃ©rents :

1. Modifier les hyperparamÃ¨tres dans le notebook
2. Relancer les cellules d'entraÃ®nement
3. Le nouveau modÃ¨le remplacera l'ancien

### ğŸ§ª Personnalisation

```python
# Modifier ces paramÃ¨tres dans le notebook :
IMG_SIZE = 224          # Taille des images
BATCH_SIZE = 32         # Taille des batches
LEARNING_RATE = 0.001   # Taux d'apprentissage
EPOCHS = 50             # Nombre d'epochs max
```

## ğŸ¤ Contribution

1. Fork du projet
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commit des changes (`git commit -am 'Add new feature'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. CrÃ©er une Pull Request


