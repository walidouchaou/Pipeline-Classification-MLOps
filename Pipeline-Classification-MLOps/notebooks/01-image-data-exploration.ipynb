{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Phase 1: Image Classification - Data Exploration and Model Training\n",
    "\n",
    "Ce notebook présente la première phase de notre projet de classification d'images. Nous allons :\n",
    "\n",
    "1. **Explorer le dataset** : Analyser la structure et le contenu du jeu de données\n",
    "2. **Visualiser les données** : Afficher des échantillons d'images de chaque classe\n",
    "3. **Prétraiter les données** : Appliquer la normalisation et l'augmentation de données\n",
    "4. **Entraîner le modèle** : Utiliser ResNet50 avec transfer learning\n",
    "5. **Évaluer les performances** : Calculer les métriques et visualiser les résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import de nos modules personnalisés\n",
    "from data_utils import DataManager\n",
    "from model_architecture import ImageClassifierBuilder, create_data_augmentation_layer, create_preprocessing_layer\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Configuration pour les graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Initialisation du DataManager et téléchargement des données\n",
    "\n",
    "Le `DataManager` gère automatiquement le téléchargement et la préparation des données depuis Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du DataManager\n",
    "data_manager = DataManager(data_dir=\"../data\")\n",
    "\n",
    "# Vérification et téléchargement du dataset si nécessaire\n",
    "if not data_manager.verify_dataset_structure():\n",
    "    print(\"Dataset non trouvé. Tentative de téléchargement...\")\n",
    "    success = data_manager.download_dataset()\n",
    "    if not success:\n",
    "        print(\"⚠️ Échec du téléchargement automatique.\")\n",
    "        print(\"Veuillez télécharger manuellement le dataset depuis:\")\n",
    "        print(\"https://www.kaggle.com/datasets/anthonytherrien/image-classification-dataset-32-classes\")\n",
    "        print(\"Et l'extraire dans le dossier '../data/raw/'\")\n",
    "else:\n",
    "    print(\"✅ Dataset trouvé et vérifié!\")\n",
    "\n",
    "# Obtenir les informations sur le dataset\n",
    "dataset_info = data_manager.get_dataset_info()\n",
    "print(f\"\\n📊 Informations sur le dataset:\")\n",
    "print(f\"Nombre de classes: {dataset_info['num_classes']}\")\n",
    "print(f\"Nombre total d'images: {dataset_info['total_images']}\")\n",
    "print(f\"Classes: {dataset_info['class_names'][:10]}...\")  # Afficher les 10 premières classes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Visualisation des Données\n",
    "\n",
    "Avant de lancer l'entraînement, visualisons quelques échantillons du dataset pour mieux comprendre nos données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des datasets pour visualisation\n",
    "if dataset_info.get('num_classes', 0) > 0:\n",
    "    # Charger un petit échantillon pour la visualisation\n",
    "    train_ds, val_ds = data_manager.load_datasets(\n",
    "        image_size=(224, 224),\n",
    "        batch_size=16,  # Plus petit batch pour la visualisation\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Visualiser quelques échantillons\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Prendre le premier batch\n",
    "    for images, labels in train_ds.take(1):\n",
    "        for i in range(min(12, len(images))):\n",
    "            plt.subplot(3, 4, i + 1)\n",
    "            # Convertir l'image en format affichable\n",
    "            img = images[i].numpy().astype(\"uint8\")\n",
    "            plt.imshow(img)\n",
    "            \n",
    "            # Obtenir le nom de la classe\n",
    "            class_idx = tf.argmax(labels[i]).numpy()\n",
    "            class_name = train_ds.class_names[class_idx]\n",
    "            plt.title(f\"Classe: {class_name}\", fontsize=10)\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"📊 Échantillons du dataset visualisés\")\n",
    "    print(f\"Classes disponibles: {train_ds.class_names}\")\n",
    "else:\n",
    "    print(\"⚠️ Dataset non disponible pour la visualisation\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Configuration de l'Entraînement\n",
    "\n",
    "Configurons les paramètres d'entraînement avant de lancer le processus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration d'entraînement\n",
    "training_config = {\n",
    "    'architecture': 'resnet50',        # Options: resnet50, efficientnet_b0, vgg16, custom_cnn\n",
    "    'epochs': 20,                      # Nombre d'époques (réduit pour le test)\n",
    "    'batch_size': 32,                  # Taille du batch\n",
    "    'learning_rate': 0.001,            # Taux d'apprentissage\n",
    "    'image_size': (224, 224),          # Taille des images\n",
    "    'validation_split': 0.2,           # Fraction pour la validation\n",
    "    'trainable_base': False,           # Transfer learning avec base gelée\n",
    "    'optimizer': 'adam',               # Optimiseur\n",
    "    'early_stopping_patience': 5      # Patience pour l'arrêt précoce\n",
    "}\n",
    "\n",
    "print(\"🔧 Configuration d'entraînement:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n💡 Conseils:\")\n",
    "print(f\"  - Commencez avec peu d'époques (10-20) pour tester\")\n",
    "print(f\"  - Utilisez ResNet50 pour de bonnes performances\")\n",
    "print(f\"  - Réduisez batch_size si vous manquez de mémoire GPU\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Lancement de l'Entraînement avec run_training\n",
    "\n",
    "Maintenant, nous allons utiliser notre script `run_training.py` directement depuis le notebook. Cela nous permet de bénéficier de toute la logique d'entraînement tout en restant dans l'environnement interactif.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du module d'entraînement\n",
    "from train import ModelTrainer\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🚀 Préparation de l'entraînement...\")\n",
    "\n",
    "# Créer une instance du trainer avec notre configuration\n",
    "trainer = ModelTrainer(training_config)\n",
    "\n",
    "print(\"✅ Trainer initialisé avec succès!\")\n",
    "print(f\"📁 Dossier de sortie: {trainer.output_dir}\")\n",
    "print(f\"📊 Dossier des logs: {trainer.log_dir}\")\n",
    "\n",
    "# Afficher un résumé avant de commencer\n",
    "print(f\"\\n📋 Résumé de l'entraînement:\")\n",
    "print(f\"  Architecture: {training_config['architecture']}\")\n",
    "print(f\"  Époques: {training_config['epochs']}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Learning rate: {training_config['learning_rate']}\")\n",
    "\n",
    "print(f\"\\n⏰ Temps estimé: ~{training_config['epochs'] * 2} minutes (selon votre matériel)\")\n",
    "print(f\"💾 Les modèles seront sauvegardés automatiquement\")\n",
    "print(f\"📈 Suivez les métriques en temps réel avec TensorBoard: tensorboard --logdir=../logs\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.1 Étape 1: Préparation des Données\n",
    "\n",
    "Cette étape télécharge le dataset (si nécessaire) et prépare les pipelines de données avec augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1: Préparation des données\n",
    "print(\"📥 Étape 1/3: Préparation des données...\")\n",
    "\n",
    "try:\n",
    "    trainer.prepare_data()\n",
    "    print(\"✅ Données préparées avec succès!\")\n",
    "    \n",
    "    # Afficher les informations sur le dataset\n",
    "    print(f\"\\n📊 Informations du dataset:\")\n",
    "    print(f\"  Nombre de classes: {trainer.dataset_info['num_classes']}\")\n",
    "    print(f\"  Total d'images: {trainer.dataset_info['total_images']}\")\n",
    "    print(f\"  Classes: {trainer.dataset_info['class_names'][:5]}... (et {trainer.dataset_info['num_classes']-5} autres)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la préparation des données: {e}\")\n",
    "    print(\"💡 Vérifiez que le dataset est disponible ou téléchargeable depuis Kaggle\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.2 Étape 2: Construction du Modèle\n",
    "\n",
    "Construction et compilation du modèle CNN avec l'architecture choisie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2: Construction du modèle\n",
    "print(\"🏗️ Étape 2/3: Construction du modèle...\")\n",
    "\n",
    "try:\n",
    "    trainer.build_model()\n",
    "    print(\"✅ Modèle construit avec succès!\")\n",
    "    \n",
    "    # Afficher un résumé du modèle\n",
    "    print(f\"\\n🧠 Résumé du modèle:\")\n",
    "    trainer.model.summary()\n",
    "    \n",
    "    # Compter les paramètres\n",
    "    total_params = trainer.model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(w) for w in trainer.model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"\\n📊 Paramètres du modèle:\")\n",
    "    print(f\"  Total: {total_params:,}\")\n",
    "    print(f\"  Entraînables: {trainable_params:,}\")\n",
    "    print(f\"  Non-entraînables: {non_trainable_params:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la construction du modèle: {e}\")\n",
    "    print(\"💡 Vérifiez la configuration du modèle\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 4.3 Étape 3: Entraînement du Modèle\n",
    "\n",
    "⚠️ **Attention**: Cette étape peut prendre du temps (plusieurs minutes à heures selon votre configuration).\n",
    "\n",
    "Le processus inclut :\n",
    "- Callbacks automatiques (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau)\n",
    "- Logging TensorBoard en temps réel\n",
    "- Sauvegarde automatique du meilleur modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3: Entraînement du modèle\n",
    "print(\"🎯 Étape 3/3: Entraînement du modèle...\")\n",
    "print(f\"⏰ Début de l'entraînement: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "try:\n",
    "    # Lancer l'entraînement\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"🎉 Entraînement terminé avec succès!\")\n",
    "    print(f\"⏰ Fin de l'entraînement: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(f\"💾 Modèle sauvegardé dans: {trainer.output_dir}\")\n",
    "    \n",
    "    # Afficher les métriques finales si disponibles\n",
    "    if trainer.history:\n",
    "        final_epoch = len(trainer.history.history['accuracy']) - 1\n",
    "        final_acc = trainer.history.history['val_accuracy'][final_epoch]\n",
    "        final_loss = trainer.history.history['val_loss'][final_epoch]\n",
    "        \n",
    "        print(f\"\\n📊 Résultats finaux:\")\n",
    "        print(f\"  Précision validation: {final_acc:.4f}\")\n",
    "        print(f\"  Perte validation: {final_loss:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de l'entraînement: {e}\")\n",
    "    print(\"💡 Vérifiez les logs ci-dessus pour plus de détails\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Visualisation des Résultats\n",
    "\n",
    "Après l'entraînement, visualisons les courbes d'apprentissage et les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats d'entraînement\n",
    "if hasattr(trainer, 'history') and trainer.history:\n",
    "    history = trainer.history.history\n",
    "    \n",
    "    # Créer les graphiques\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Précision\n",
    "    axes[0, 0].plot(history['accuracy'], label='Entraînement', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    axes[0, 0].set_title('Précision du Modèle', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Époque')\n",
    "    axes[0, 0].set_ylabel('Précision')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Perte\n",
    "    axes[0, 1].plot(history['loss'], label='Entraînement', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "    axes[0, 1].set_title('Perte du Modèle', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Époque')\n",
    "    axes[0, 1].set_ylabel('Perte')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top-3 Accuracy\n",
    "    if 'top_3_accuracy' in history:\n",
    "        axes[1, 0].plot(history['top_3_accuracy'], label='Entraînement Top-3', linewidth=2)\n",
    "        axes[1, 0].plot(history['val_top_3_accuracy'], label='Validation Top-3', linewidth=2)\n",
    "        axes[1, 0].set_title('Précision Top-3', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Époque')\n",
    "        axes[1, 0].set_ylabel('Précision Top-3')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Top-5 Accuracy\n",
    "    if 'top_5_accuracy' in history:\n",
    "        axes[1, 1].plot(history['top_5_accuracy'], label='Entraînement Top-5', linewidth=2)\n",
    "        axes[1, 1].plot(history['val_top_5_accuracy'], label='Validation Top-5', linewidth=2)\n",
    "        axes[1, 1].set_title('Précision Top-5', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Époque')\n",
    "        axes[1, 1].set_ylabel('Précision Top-5')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Résumé des performances\n",
    "    print(\"📊 Résumé des Performances:\")\n",
    "    print(f\"  Meilleure précision validation: {max(history['val_accuracy']):.4f}\")\n",
    "    print(f\"  Perte finale validation: {history['val_loss'][-1]:.4f}\")\n",
    "    if 'val_top_3_accuracy' in history:\n",
    "        print(f\"  Meilleure précision Top-3: {max(history['val_top_3_accuracy']):.4f}\")\n",
    "    if 'val_top_5_accuracy' in history:\n",
    "        print(f\"  Meilleure précision Top-5: {max(history['val_top_5_accuracy']):.4f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Aucun historique d'entraînement disponible pour la visualisation\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Prochaines Étapes\n",
    "\n",
    "🎉 **Félicitations !** Vous avez terminé la Phase 1 du projet MLOps.\n",
    "\n",
    "### Ce que vous avez accompli :\n",
    "- ✅ Exploration et visualisation du dataset\n",
    "- ✅ Entraînement d'un modèle CNN avec transfer learning\n",
    "- ✅ Évaluation des performances\n",
    "- ✅ Sauvegarde automatique du modèle\n",
    "\n",
    "### Prochaines étapes suggérées :\n",
    "\n",
    "1. **Optimisation du modèle** :\n",
    "   - Essayer différentes architectures (EfficientNet, VGG16)\n",
    "   - Ajuster les hyperparamètres\n",
    "   - Fine-tuning avec `trainable_base=True`\n",
    "\n",
    "2. **Phase 2 - Classification de texte** :\n",
    "   - Implémenter un modèle NLP\n",
    "   - Utiliser des transformers (BERT, etc.)\n",
    "\n",
    "3. **Phase 3 - API REST** :\n",
    "   - Créer une API FastAPI\n",
    "   - Déployer le modèle en production\n",
    "\n",
    "4. **Monitoring et MLOps** :\n",
    "   - Mise en place de pipelines CI/CD\n",
    "   - Monitoring des performances en production\n",
    "\n",
    "### Commandes utiles :\n",
    "\n",
    "```bash\n",
    "# Visualiser les métriques avec TensorBoard\n",
    "tensorboard --logdir=../logs\n",
    "\n",
    "# Tester différentes configurations\n",
    "python ../run_training.py\n",
    "\n",
    "# Voir les modèles sauvegardés\n",
    "ls ../models/\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
