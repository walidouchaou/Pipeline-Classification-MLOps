{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üöÄ Classification de Texte avec Hugging Face Transformers\n",
        "\n",
        "Ce notebook pr√©sente un pipeline complet de **classification de texte** utilisant **DistilBERT** et la biblioth√®que **Transformers** de Hugging Face.\n",
        "\n",
        "## üìã Table des Mati√®res\n",
        "1. [Installation des D√©pendances](#dependencies)\n",
        "2. [Chargement du Dataset AG News](#dataset)\n",
        "3. [Justification du Choix du Mod√®le](#model-choice)\n",
        "4. [Tokenisation des Donn√©es](#tokenization)\n",
        "5. [Fine-tuning du Mod√®le](#training)\n",
        "6. [√âvaluation des Performances](#evaluation)\n",
        "7. [Sauvegarde du Mod√®le](#save)\n",
        "8. [Tests de Pr√©diction](#prediction)\n",
        "\n",
        "## üéØ Objectif\n",
        "D√©velopper un classifieur de texte capable de **cat√©goriser automatiquement des articles de presse** en 4 cat√©gories : World, Sports, Business, et Sci/Tech.\n",
        "\n",
        "## üìä R√©sultats Attendus\n",
        "- **üéØ Accuracy**: ~92% sur le jeu de test\n",
        "- **üìà Dataset**: AG News (127,600 articles)\n",
        "- **üèóÔ∏è Architecture**: DistilBERT fine-tun√©\n",
        "- **‚ö° Temps d'entra√Ænement**: ~10 epochs\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Installation des D√©pendances {#dependencies}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeARVBTshhoy",
        "outputId": "15a79f2f-5c24-49bf-cd06-58ebcf18014c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Biblioth√®ques install√©es.\n"
          ]
        }
      ],
      "source": [
        "# Installation des biblioth√®ques Hugging Face et de scikit-learn pour l'√©valuation\n",
        "!pip install -q datasets transformers torch scikit-learn\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques install√©es.\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyagBn4skF8L",
        "outputId": "0dd95608-c2a4-4b84-bf85-94d9b73f2767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (1.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade datasets transformers huggingface-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Chargement du Dataset AG News {#dataset}\n",
        "\n",
        "### üì∞ √Ä Propos d'AG News\n",
        "Le dataset **AG News** est un benchmark populaire pour la classification de texte :\n",
        "\n",
        "- **üìä Taille**: 127,600 articles de presse\n",
        "- **üìã Classes**: 4 cat√©gories d'actualit√©s\n",
        "- **üéØ Task**: Classification multi-classe\n",
        "- **üìà Split**: 120K train / 7.6K test\n",
        "\n",
        "### üè∑Ô∏è Classes Disponibles:\n",
        "1. **World** (0) - Actualit√©s mondiales\n",
        "2. **Sports** (1) - Actualit√©s sportives  \n",
        "3. **Business** (2) - Actualit√©s √©conomiques\n",
        "4. **Sci/Tech** (3) - Sciences et technologie\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7k4Juhjh2NE",
        "outputId": "2068cf37-345b-4add-f51e-894b64e2d370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Jeu de donn√©es 'ag_news' charg√© avec succ√®s.\n",
            "\n",
            "Structure du jeu de donn√©es :\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 120000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 7600\n",
            "    })\n",
            "})\n",
            "\n",
            "--- Exemple de donn√©e (train) ---\n",
            "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n",
            "\n",
            "Labels : [(0, 'World'), (1, 'Sports'), (2, 'Business'), (3, 'Sci/Tech')]\n",
            "Texte : 'Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.'\n",
            "Label : 2 (Business)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Chargement du jeu de donn√©es AG News\n",
        "try:\n",
        "    raw_datasets = load_dataset(\"ag_news\")\n",
        "    print(\"‚úÖ Jeu de donn√©es 'ag_news' charg√© avec succ√®s.\")\n",
        "    print(\"\\nStructure du jeu de donn√©es :\")\n",
        "    print(raw_datasets)\n",
        "\n",
        "    # Affichage d'un exemple pour comprendre la structure\n",
        "    print(\"\\n--- Exemple de donn√©e (train) ---\")\n",
        "    example = raw_datasets['train'][0]\n",
        "    print(example)\n",
        "\n",
        "    # Les labels sont des entiers, cr√©ons un mappage pour la lisibilit√©\n",
        "    label_names = raw_datasets['train'].features['label'].names\n",
        "    print(f\"\\nLabels : {list(enumerate(label_names))}\")\n",
        "    print(f\"Texte : '{example['text']}'\")\n",
        "    print(f\"Label : {example['label']} ({label_names[example['label']]})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erreur lors du chargement du jeu de donn√©es : {e}\")\n",
        "    print(\"Il est possible que le service Hugging Face Hub soit temporairement indisponible.\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rpv-dO2iCDK"
      },
      "source": [
        "Justification du Choix du Mod√®le : DistilBERT\n",
        "Pour cette t√¢che, nous allons choisir distilbert-base-uncased. C'est un choix strat√©gique pour plusieurs raisons :\n",
        "\n",
        "Efficacit√© : DistilBERT est une version \"distill√©e\" de BERT. Il est environ 60% plus rapide et plus l√©ger que BERT, tout en conservant plus de 95% de ses performances.\n",
        "Adapt√© √† Colab : Sa l√©g√®ret√© le rend id√©al pour un fine-tuning sur des ressources limit√©es comme celles de Google Colab, permettant des it√©rations plus rapides.\n",
        "Performance : Il offre un excellent compromis entre vitesse et pr√©cision pour les t√¢ches de classification de texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Tokenisation des Donn√©es {#tokenization}\n",
        "\n",
        "### üî§ Processus de Tokenisation\n",
        "\n",
        "La tokenisation transforme le texte brut en tokens num√©riques compr√©hensibles par le mod√®le :\n",
        "\n",
        "#### üîß √âtapes de Tokenisation:\n",
        "1. **Segmentation**: Division en sous-mots (WordPiece)\n",
        "2. **Mapping**: Conversion en IDs num√©riques\n",
        "3. **Padding**: Uniformisation de la longueur\n",
        "4. **Truncation**: Limitation √† 512 tokens max\n",
        "\n",
        "#### ‚öôÔ∏è Configuration:\n",
        "- **Tokenizer**: `distilbert-base-uncased`\n",
        "- **Max Length**: 512 tokens\n",
        "- **Padding**: Dynamique √† la longueur max du batch\n",
        "- **Truncation**: Activ√©e pour les textes longs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4e92c0a157304f16bd1f2b367685e013",
            "c4fe55fe2ef74d46bdaaa564bcc6e584",
            "f47021eb40304718abb04063a8e558d0",
            "59784759b64f401badd97790c64bcb10",
            "bb50290f95ee48f896dd133b3367d6e4",
            "0f61b1b772b04b378fa01652c929b874",
            "7a68b3673f564bfabcb221b05b75812e",
            "4611d6f6e1714ec88394dab266da1120",
            "85a2cc825c9746b6813bcd70b5f7dc2f",
            "3a5ea576dae743e791e33520092068fc",
            "e45f7bc9d4e0490590019541ad7c906e"
          ]
        },
        "id": "lfpNDW0xiD-m",
        "outputId": "a8abd69b-30ed-4a79-fed2-98d257034e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Tokenisation des donn√©es en cours...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e92c0a157304f16bd1f2b367685e013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Donn√©es tokenis√©es.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Chargement du tokenizer associ√© √† DistilBERT\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Fonction pour tokeniser les textes\n",
        "def tokenize_function(examples):\n",
        "    # padding=True et truncation=True assurent que toutes les s√©quences ont la m√™me longueur\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Appliquer la fonction de tokenisation √† l'ensemble du jeu de donn√©es\n",
        "# batched=True permet de traiter les donn√©es par lots pour plus de rapidit√©\n",
        "print(\"üîÑ Tokenisation des donn√©es en cours...\")\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "print(\"‚úÖ Donn√©es tokenis√©es.\")\n",
        "\n",
        "# On peut retirer la colonne \"text\" qui n'est plus n√©cessaire et renommer \"label\" en \"labels\"\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Cr√©ation de sous-ensembles pour un entra√Ænement plus rapide\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(10000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fine-tuning du Mod√®le {#training}\n",
        "\n",
        "### üéØ Configuration d'Entra√Ænement\n",
        "\n",
        "#### ‚öôÔ∏è Hyperparam√®tres:\n",
        "- **Learning Rate**: 2e-5 (recommand√© pour BERT-family)\n",
        "- **Batch Size**: 16 (train) / 16 (eval)\n",
        "- **Epochs**: 10 (avec early stopping)\n",
        "- **Weight Decay**: 0.01 (r√©gularisation L2)\n",
        "- **Optimizer**: AdamW (optimiseur par d√©faut)\n",
        "\n",
        "#### üìä Strat√©gie d'Entra√Ænement:\n",
        "1. **Subset Training**: 10K √©chantillons (entra√Ænement rapide)\n",
        "2. **√âvaluation**: 1K √©chantillons de validation\n",
        "3. **Monitoring**: Loss de validation √† chaque epoch\n",
        "4. **Sauvegarde**: Meilleur mod√®le automatiquement sauv√©\n",
        "\n",
        "### üöÄ Avantages du Fine-tuning:\n",
        "- **Transfer Learning**: Exploitation des connaissances pr√©-acquises\n",
        "- **Adaptation**: Sp√©cialisation sur le domaine des actualit√©s\n",
        "- **Efficacit√©**: Moins de donn√©es requises qu'un entra√Ænement from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "NYpszQ1dk0Eg",
        "outputId": "fa92a00e-a5e5-45f5-a0d6-37d146ae4197"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üöÄ D√©but du fine-tuning...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6250/6250 17:14, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.284693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.244600</td>\n",
              "      <td>0.296621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.311361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.093200</td>\n",
              "      <td>0.360529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.058100</td>\n",
              "      <td>0.393590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>0.447178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.479264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.521314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.528451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.537483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fine-tuning termin√©.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Chargement du mod√®le pr√©-entra√Æn√©, en sp√©cifiant le nombre de classes (4 pour AG News)\n",
        "# Assurez-vous que la variable 'model_checkpoint' est bien d√©finie (ex: \"distilbert-base-uncased\")\n",
        "# et que 'small_train_dataset' et 'small_eval_dataset' existent.\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4)\n",
        "\n",
        "# D√©finition des arguments pour l'entra√Ænement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"Pipeline-Classification-MLOps/models/huggingFace/results\",\n",
        "\n",
        "    # --- CORRECTION APPLIQU√âE ICI ---\n",
        "    eval_strategy=\"epoch\", # Remplacement de \"evaluation_strategy\" par \"eval_strategy\"\n",
        "    # ---------------------------------\n",
        "\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/drive/MyDrive/TP/huginface/logs',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Cr√©ation de l'objet Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        ")\n",
        "\n",
        "# Lancement du fine-tuning\n",
        "print(\"\\nüöÄ D√©but du fine-tuning...\")\n",
        "trainer.train()\n",
        "print(\"‚úÖ Fine-tuning termin√©.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. √âvaluation des Performances {#evaluation}\n",
        "\n",
        "### üìä M√©triques d'√âvaluation\n",
        "\n",
        "Nous utilisons plusieurs m√©triques pour √©valuer la performance de notre mod√®le :\n",
        "\n",
        "#### üéØ M√©triques Principales:\n",
        "- **Accuracy**: Pourcentage de pr√©dictions correctes\n",
        "- **Precision**: Exactitude des pr√©dictions positives\n",
        "- **Recall**: Capacit√© √† identifier tous les cas positifs\n",
        "- **F1-Score**: Moyenne harmonique de Precision et Recall\n",
        "\n",
        "#### üìà R√©sultats Attendus:\n",
        "- **Accuracy globale**: ~92%\n",
        "- **Performance par classe**: √âquilibr√©e entre les 4 cat√©gories\n",
        "- **Meilleure classe**: Sports (textes distinctifs)\n",
        "- **Plus difficile**: Business vs World (overlap possible)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "uK9kqzuPk2uD",
        "outputId": "99e516a6-f623-4bbc-8068-aec6e3229920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä √âvaluation des performances sur l'ensemble de test...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Rapport de Classification ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       World       0.96      0.91      0.93       266\n",
            "      Sports       0.98      0.99      0.98       246\n",
            "    Business       0.89      0.87      0.88       246\n",
            "    Sci/Tech       0.84      0.89      0.86       242\n",
            "\n",
            "    accuracy                           0.92      1000\n",
            "   macro avg       0.92      0.92      0.91      1000\n",
            "weighted avg       0.92      0.92      0.92      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\nüìä √âvaluation des performances sur l'ensemble de test...\")\n",
        "\n",
        "# Obtenir les pr√©dictions du mod√®le sur le jeu de test\n",
        "predictions = trainer.predict(small_eval_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "true_labels = small_eval_dataset[\"label\"]\n",
        "\n",
        "# Afficher le rapport de classification\n",
        "print(\"\\n--- Rapport de Classification ---\")\n",
        "print(classification_report(true_labels, predicted_labels, target_names=label_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sauvegarde du Mod√®le {#save}\n",
        "\n",
        "### üíæ Strat√©gie de Sauvegarde\n",
        "\n",
        "Le mod√®le et le tokenizer sont sauvegard√©s ensemble pour assurer la reproductibilit√© :\n",
        "\n",
        "#### üîß √âl√©ments Sauvegard√©s:\n",
        "- **Mod√®le DistilBERT** fine-tun√© (.bin)\n",
        "- **Tokenizer** avec vocabulaire (.json)\n",
        "- **Configuration** du mod√®le (.json)\n",
        "- **M√©tadonn√©es** d'entra√Ænement\n",
        "\n",
        "#### üìÅ Structure de Sauvegarde:\n",
        "```\n",
        "Pipeline-Classification-MLOps/models/huggingFace/\n",
        "‚îî‚îÄ‚îÄ text-classifier-ag-news-distilbert/\n",
        "    ‚îú‚îÄ‚îÄ config.json\n",
        "    ‚îú‚îÄ‚îÄ pytorch_model.bin\n",
        "    ‚îú‚îÄ‚îÄ tokenizer_config.json\n",
        "    ‚îú‚îÄ‚îÄ tokenizer.json\n",
        "    ‚îî‚îÄ‚îÄ vocab.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOe3xkigk4-Q",
        "outputId": "34bce723-2117-41aa-a510-2375c1779680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Mod√®le et tokenizer sauvegard√©s dans le dossier : '/content/drive/MyDrive/TP/huginface/text-classifier-ag-news-distilbert'\n"
          ]
        }
      ],
      "source": [
        "# D√©finition du dossier de sauvegarde\n",
        "output_model_dir = \"Pipeline-Classification-MLOps/models/huggingFace/text-classifier-ag-news-distilbert\"\n",
        "\n",
        "# Sauvegarde du mod√®le et du tokenizer\n",
        "trainer.save_model(output_model_dir)\n",
        "tokenizer.save_pretrained(output_model_dir)\n",
        "\n",
        "print(f\"\\n‚úÖ Mod√®le et tokenizer sauvegard√©s dans le dossier : '{output_model_dir}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Tests de Pr√©diction en Production {#prediction}\n",
        "\n",
        "### üß™ Suite de Tests Compl√®te\n",
        "\n",
        "Cette section valide les performances du mod√®le sur diff√©rents types de textes :\n",
        "\n",
        "#### üéØ Types de Tests:\n",
        "\n",
        "1. **Tests Simples** üü¢\n",
        "   - Textes √©vidents pour chaque cat√©gorie\n",
        "   - Validation des cas d'usage basiques\n",
        "\n",
        "2. **Tests Ambigus** üü°\n",
        "   - Articles avec √©l√©ments de plusieurs cat√©gories\n",
        "   - Test de la robustesse du mod√®le\n",
        "\n",
        "3. **Tests Hors Distribution** üî¥\n",
        "   - Textes non-journalistiques (cuisine, etc.)\n",
        "   - √âvaluation de la g√©n√©ralisation\n",
        "\n",
        "#### üìä M√©triques de Confiance:\n",
        "- **Tr√®s Haute** (>95%): Pr√©diction fiable\n",
        "- **Haute** (80-95%): Pr√©diction probable\n",
        "- **Mod√©r√©e** (60-80%): Incertitude du mod√®le\n",
        "- **Faible** (<60%): Pr√©diction peu fiable\n",
        "\n",
        "### üéØ Objectifs des Tests:\n",
        "- V√©rifier la **robustesse** du mod√®le\n",
        "- Identifier les **cas limites**\n",
        "- Tester la **g√©n√©ralisation** hors domaine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WykfpgfVscR6",
        "outputId": "cd0b4be1-24b1-493a-8c3b-9f1b6c757d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- D√©but du test pour le mod√®le : /content/drive/MyDrive/TP/huginface/text-classifier-ag-news-distilbert ---\n",
            "üîÑ Chargement du mod√®le et du tokenizer...\n",
            "‚úÖ Mod√®le et tokenizer charg√©s avec succ√®s.\n",
            "----------------------------------------\n",
            "üî¨ Test en cours : Cas Simple (Sport)\n",
            "   Texte : \"The team won the championship final after a thrilling match.\"\n",
            "\n",
            "--- R√âSULTAT DE LA PR√âDICTION ---\n",
            "üéØ Classe pr√©dite : Sports\n",
            "üíØ Confiance : 99.96%\n",
            "----------------------------------------\n",
            "üî¨ Test en cours : Cas Simple (Business)\n",
            "   Texte : \"The company's stock price surged after announcing record profits for the quarter.\"\n",
            "\n",
            "--- R√âSULTAT DE LA PR√âDICTION ---\n",
            "üéØ Classe pr√©dite : Business\n",
            "üíØ Confiance : 99.95%\n",
            "----------------------------------------\n",
            "üî¨ Test en cours : Cas Simple (Sci/Tech)\n",
            "   Texte : \"Researchers have developed a new AI that can write compelling short stories.\"\n",
            "\n",
            "--- R√âSULTAT DE LA PR√âDICTION ---\n",
            "üéØ Classe pr√©dite : Sci/Tech\n",
            "üíØ Confiance : 99.91%\n",
            "----------------------------------------\n",
            "üî¨ Test en cours : Cas Ambigu (Sport/Business/Tech)\n",
            "   Texte : \"Formula 1 announced new engine regulations powered by sustainable fuels to reduce costs.\"\n",
            "\n",
            "--- R√âSULTAT DE LA PR√âDICTION ---\n",
            "üéØ Classe pr√©dite : World\n",
            "üíØ Confiance : 58.57%\n",
            "----------------------------------------\n",
            "üî¨ Test en cours : Cas Hors Distribution (Cuisine)\n",
            "   Texte : \"The recipe for this cake requires two cups of flour and a pinch of salt.\"\n",
            "\n",
            "--- R√âSULTAT DE LA PR√âDICTION ---\n",
            "üéØ Classe pr√©dite : Sci/Tech\n",
            "üíØ Confiance : 95.63%\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# --- Configuration ---\n",
        "# MODIFIEZ CE NOM si votre dossier de mod√®le est diff√©rent\n",
        "MODEL_DIR = \"Pipeline-Classification-MLOps/models/huggingFace/text-classifier-ag-news-distilbert\"\n",
        "\n",
        "# Les noms des classes dans l'ordre de leur index (0, 1, 2, 3)\n",
        "CLASS_NAMES = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "# --- Phrases de test ---\n",
        "test_sentences = {\n",
        "    \"Cas Simple (Sport)\": \"The team won the championship final after a thrilling match.\",\n",
        "    \"Cas Simple (Business)\": \"The company's stock price surged after announcing record profits for the quarter.\",\n",
        "    \"Cas Simple (Sci/Tech)\": \"Researchers have developed a new AI that can write compelling short stories.\",\n",
        "    \"Cas Ambigu (Sport/Business/Tech)\": \"Formula 1 announced new engine regulations powered by sustainable fuels to reduce costs.\",\n",
        "    \"Cas Hors Distribution (Cuisine)\": \"The recipe for this cake requires two cups of flour and a pinch of salt.\"\n",
        "}\n",
        "\n",
        "\n",
        "def predict(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Effectue une pr√©diction sur une seule cha√Æne de caract√®res.\n",
        "    \"\"\"\n",
        "    # 1. Tokeniser le texte d'entr√©e\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # 2. Effectuer la pr√©diction\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # 3. Interpr√©ter les r√©sultats\n",
        "    # Appliquer Softmax pour convertir les logits en probabilit√©s\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    # Obtenir la classe pr√©dite et la confiance\n",
        "    confidence, predicted_class_idx = torch.max(probabilities, dim=-1)\n",
        "    predicted_class = CLASS_NAMES[predicted_class_idx.item()]\n",
        "\n",
        "    return predicted_class, confidence.item()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fonction principale pour charger le mod√®le et lancer les tests.\n",
        "    \"\"\"\n",
        "    print(f\"--- D√©but du test pour le mod√®le : {MODEL_DIR} ---\")\n",
        "\n",
        "    # 1. V√©rifier si le dossier du mod√®le existe\n",
        "    if not os.path.exists(MODEL_DIR):\n",
        "        print(f\"‚ùå Erreur : Le dossier du mod√®le '{MODEL_DIR}' n'a pas √©t√© trouv√©.\")\n",
        "        return\n",
        "\n",
        "    # 2. Charger le mod√®le et le tokenizer sauvegard√©s\n",
        "    try:\n",
        "        print(\"üîÑ Chargement du mod√®le et du tokenizer...\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "        print(\"‚úÖ Mod√®le et tokenizer charg√©s avec succ√®s.\")\n",
        "        # Mettre le mod√®le en mode √©valuation\n",
        "        model.eval()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur lors du chargement : {e}\")\n",
        "        return\n",
        "\n",
        "    # 3. Lancer les tests sur les diff√©rentes phrases\n",
        "    for test_name, sentence in test_sentences.items():\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"üî¨ Test en cours : {test_name}\")\n",
        "        print(f\"   Texte : \\\"{sentence}\\\"\")\n",
        "\n",
        "        predicted_class, confidence = predict(sentence, model, tokenizer)\n",
        "\n",
        "        print(\"\\n--- R√âSULTAT DE LA PR√âDICTION ---\")\n",
        "        print(f\"üéØ Classe pr√©dite : {predicted_class}\")\n",
        "        print(f\"üíØ Confiance : {confidence:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f61b1b772b04b378fa01652c929b874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5ea576dae743e791e33520092068fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4611d6f6e1714ec88394dab266da1120": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e92c0a157304f16bd1f2b367685e013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4fe55fe2ef74d46bdaaa564bcc6e584",
              "IPY_MODEL_f47021eb40304718abb04063a8e558d0",
              "IPY_MODEL_59784759b64f401badd97790c64bcb10"
            ],
            "layout": "IPY_MODEL_bb50290f95ee48f896dd133b3367d6e4"
          }
        },
        "59784759b64f401badd97790c64bcb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5ea576dae743e791e33520092068fc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e45f7bc9d4e0490590019541ad7c906e",
            "value": "‚Äá7600/7600‚Äá[00:01&lt;00:00,‚Äá4762.02‚Äáexamples/s]"
          }
        },
        "7a68b3673f564bfabcb221b05b75812e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a2cc825c9746b6813bcd70b5f7dc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb50290f95ee48f896dd133b3367d6e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fe55fe2ef74d46bdaaa564bcc6e584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f61b1b772b04b378fa01652c929b874",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a68b3673f564bfabcb221b05b75812e",
            "value": "Map:‚Äá100%"
          }
        },
        "e45f7bc9d4e0490590019541ad7c906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47021eb40304718abb04063a8e558d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4611d6f6e1714ec88394dab266da1120",
            "max": 7600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85a2cc825c9746b6813bcd70b5f7dc2f",
            "value": 7600
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
